{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImagenesTF.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "f2pv0ZSHo4Gy"
      ],
      "authorship_tag": "ABX9TyN2CdP7nc40LoVmgwMkzwmt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pepedp/COVID-19/blob/master/ImagenesTF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nRXDrUQCe89",
        "colab_type": "text"
      },
      "source": [
        "![texto alternativo](https://soyoungpark.github.io/assets/images/tensorflowtraffic/tf.png)\n",
        "\n",
        "REFERENCIA - TENSORFLOW: \n",
        "\n",
        " - https://www.tensorflow.org/tutorials/keras/classification \n",
        "\n",
        "\n",
        "REFERENCIA - KERAS: \n",
        "\n",
        " - https://torres.ai/deep-learning-inteligencia-artificial-keras/\n",
        "\n",
        " - https://torres.ai/deep-learning-inteligencia-artificial-keras-2a-parte/\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8_XP9mdhix5",
        "colab_type": "text"
      },
      "source": [
        "**Descripción del Ejemplo**\n",
        "\n",
        "El laboratorio consiste en crear una Inteligencia Artificial capas de categorizar imagenes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e04Wf080iSbx",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Librerias y Funciones \n",
        "#Librerias  \n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "from tqdm import tqdm_notebook\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator #Procesado de imagenes \n",
        "%matplotlib inline\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "#Habilitar TensroBoard \n",
        "import datetime\n",
        "%load_ext tensorboard\n",
        "!rm -rf ./logs/ \n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "\n",
        "#FUNCIONES \n",
        "#Funcion para desplegar imagenes \n",
        "clasificacion=[]\n",
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        " \n",
        "  plt.imshow(img, cmap=plt.cm.binary)\n",
        " \n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        " \n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(clasificacion[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                clasificacion[true_label]),\n",
        "                                color=color)\n",
        " \n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "  predictions_array, true_label = predictions_array, true_label[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks(range(10))\n",
        "  plt.yticks([])\n",
        "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
        "  plt.ylim([0, 1])\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        " \n",
        "  thisplot[predicted_label].set_color('red')\n",
        "  thisplot[true_label].set_color('blue')\n",
        "\n",
        "#Funcion para ajustar registro grafico barras \n",
        "def autolabel(rects):\n",
        "  for rect in rects:\n",
        "      height = rect.get_height()\n",
        "      plt.annotate('{}'.format(height),\n",
        "                  xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                  xytext=(0, 3),  # 3 points vertical offset\n",
        "                  textcoords=\"offset points\",\n",
        "                  ha=\"center\", va='bottom')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2pv0ZSHo4Gy",
        "colab_type": "text"
      },
      "source": [
        "# Procesar Imagenes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBIol_bUiYSg",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Cargar imagenes \n",
        "dataset_numeros = False #@param {type:\"boolean\"}\n",
        "dataset_transporte = False #@param {type:\"boolean\"}\n",
        "imag_mostrar = 20 #@param {type:\"slider\", min:5, max:100, step:5}\n",
        " \n",
        "if (dataset_numeros):\n",
        "  nombre_dataset=\"mnist\"\n",
        "  dataset_imagenes = tf.keras.datasets.mnist #Dataset que ya vienen en la libreria Tensoflow.keras\n",
        "  clasificacion = ['Cero','Uno', 'Dos', 'tres', 'Cuatro', \n",
        "                   'Cinco','Seis', 'Siete', 'Ocho', 'Nueve']\n",
        "elif(dataset_transporte):\n",
        "  nombre_dataset=\"cifar10\"\n",
        "  dataset_imagenes = tf.keras.datasets.cifar10 \n",
        "  clasificacion = ['avión', 'coche', 'pájaro', 'gato', 'ciervo', \n",
        "                   'perro', 'rana', 'caballo', 'barco', 'camión']\n",
        "else:\n",
        "  nombre_dataset=\"fashion_mnist\"\n",
        "  dataset_imagenes=tf.keras.datasets.fashion_mnist\n",
        "  clasificacion = ['Camiseta/top', 'Pantalón', 'Suéter', 'Vestido', 'Saco',\n",
        "                   'Sandalia', 'Camisa', 'Sneaker', 'Bolso', 'Botín']\n",
        " \n",
        "  \"\"\"clasificacion = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "                   'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\"\"\"\n",
        " \n",
        "(x_train, y_train), (x_test, y_test) = dataset_imagenes.load_data()\n",
        "tipo_imagen=\"a color (RBG)\" if x_train.ndim>3 else \"en escala de grises\"\n",
        "y_train,y_test=y_train.flatten(),y_test.flatten()\n",
        "\n",
        "print(\"DATASET: {}\".format(nombre_dataset) )\n",
        "print(\"\"\"ENTRENAMIENTO: \\nx_train: Dimension del array[{}] | Shape:[{}] \n",
        "y_train: Dimension del array[{}] | Shape:[{}] \n",
        "\\nTEST \\nx_test: Dimension del array[{}] | Shape:[{}] \n",
        "y_test: Dimension del array[{}] | Shape:[{}] \n",
        "\\nRESUMEN\n",
        " - Tamaño de cada imagen {}x{} píxeles {}\n",
        " - {:,.0f} imagenes de entrenamieno\n",
        " - {:,.0f} imagenes de test \n",
        " - y_train & y_test contienen la categoria que pertenece la imagen (10 categorias)\n",
        "\"\"\".format(x_train.ndim,x_train.shape,\n",
        "           y_train.ndim,y_train.shape,\n",
        "           x_test.ndim,x_test.shape,\n",
        "           y_test.ndim,y_test.shape,\n",
        "           x_train.shape[1],x_train.shape[2],tipo_imagen,\n",
        "           x_train.shape[0],\n",
        "           x_test.shape[0]           \n",
        "           ))\n",
        "\n",
        "#imag_mostrar=200\n",
        "alto, ancho = 10,imag_mostrar/2\n",
        "print(\"Primeras {} imagenes\".format(imag_mostrar))\n",
        "fig=plt.figure(figsize=(alto,ancho))\n",
        "for i in range(imag_mostrar):\n",
        "    ax=fig.add_subplot(imag_mostrar/5,5,i+1)\n",
        "    ax.xaxis.label.set_color(\"white\")\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(x_train[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(clasificacion[y_train[i]] )\n",
        "plt.show()\n",
        "print(\"Respuesta: {}\".format(y_train[:imag_mostrar]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr79k1i2GMQj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0c--gSQrA6E",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Datos de la imagen \n",
        "Numero_imagen =  1#@param {type:\"integer\"}\n",
        "if Numero_imagen!=0:\n",
        "  np.set_printoptions(edgeitems=5, linewidth=1000, \n",
        "      formatter=dict(float=lambda x: \"%.3g\" % x))\n",
        "  print(\"Respuesta: {}\".format(y_train[Numero_imagen-1:Numero_imagen]) )\n",
        "  print(x_train[Numero_imagen-1])\n",
        "else:\n",
        "  print(\"Imagen cero no existe, debe ser mayor a cero\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTiKTtr_mRBb",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Redimensionar Dataset\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5t2kxG0qeGs",
        "colab_type": "text"
      },
      "source": [
        "**Arquitectura de la red Neuronal**\n",
        "\n",
        " - RNA: Arquitectura de Red Neuronal Artificial, \n",
        " - RNC: Arquitectura de Red Neuronal Convolucional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxU8pRjc4Ii9",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Crear Red Neuronal\n",
        "RNA = False #@param {type:\"boolean\"}\n",
        "RNC = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "if RNC==True and RNA==False:\n",
        "  modelo = tf.keras.models.Sequential()\n",
        "  if x_train.ndim<4:\n",
        "    modelo.add(tf.keras.layers.Conv1D(filters=28, kernel_size=3, padding=\"same\", activation=\"relu\", \n",
        "                                      input_shape=[x_train.shape[1], x_train.shape[2]]) )\n",
        "    modelo.add(tf.keras.layers.Conv1D(filters=28, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
        "    modelo.add(tf.keras.layers.MaxPool1D(pool_size=2, strides=2, padding='valid'))\n",
        "    modelo.add(tf.keras.layers.Conv1D(filters=56, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
        "    modelo.add(tf.keras.layers.Conv1D(filters=56, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
        "    modelo.add(tf.keras.layers.MaxPool1D(pool_size=2, strides=2, padding='valid'))\n",
        "    modelo.add(tf.keras.layers.Flatten())\n",
        "    modelo.add(tf.keras.layers.Dense(units=128, activation='relu'))\n",
        "    modelo.add(tf.keras.layers.Dropout(0.3))\n",
        "    modelo.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
        "    modelo.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
        "    modelo.summary()\n",
        "    \n",
        "  else:\n",
        "    modelo.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", \n",
        "                                      input_shape=[x_train.shape[1], x_train.shape[2],x_train.shape[3]]) )  \n",
        "    #modelo.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=[32, 32, 3]) )\n",
        "    modelo.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
        "    modelo.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n",
        "    modelo.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
        "    modelo.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\"))\n",
        "    modelo.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding='valid'))\n",
        "    modelo.add(tf.keras.layers.Flatten())\n",
        "    modelo.add(tf.keras.layers.Dense(units=300, activation='relu'))\n",
        "    modelo.add(tf.keras.layers.Dropout(0.2))\n",
        "    modelo.add(tf.keras.layers.Dense(units=300, activation='relu'))\n",
        "    modelo.add(tf.keras.layers.Dropout(0.2))\n",
        "    modelo.add(tf.keras.layers.Dense(units=200, activation='relu'))\n",
        "    #modelo.add(tf.keras.layers.Dropout(0.3))\n",
        "    modelo.add(tf.keras.layers.Dense(units=10, activation='softmax'))\n",
        "    modelo.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
        "    modelo.summary()\n",
        "  \n",
        "elif RNC==False and RNA==True:\n",
        "  modelo = tf.keras.models.Sequential() #inicializamos el modelo (Creamos el objeto modelo) \n",
        "  if x_train.ndim<4:\n",
        "    modelo.add(tf.keras.layers.Flatten(input_shape=(x_train.shape[1], x_train.shape[2]) )) #784 Variables de entrada espera la Red Neuronal (28*28=784)\n",
        "  else:\n",
        "    modelo.add(tf.keras.layers.Flatten(input_shape=(x_train.shape[1], x_train.shape[2],x_train.shape[3]) ))\n",
        "  modelo.add(tf.keras.layers.Dense(128, activation='relu')) #128 Neuronas, función de activación Relu\n",
        "  modelo.add(tf.keras.layers.Dropout(0.3))  #Neuronas que desactivamos para el entrenamiento (20%) evitar overfitting\n",
        "  modelo.add(tf.keras.layers.Dense(10)) #La salida = 10; que es igual a la cantidad de clasificaciones del dataset\n",
        "  modelo.add(tf.keras.layers.Dense(units=10, activation='softmax')) #Función de salida para la clasificación y probabilidad\n",
        "  modelo.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n",
        "  modelo.summary()\n",
        "\n",
        "else:\n",
        "  print (\"Solo seleccionar solo una arquitectura\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzW7c-6ntPp-",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Entrenar a la Red Neuronal\n",
        "Entrenamiento =  5#@param {type:\"number\"}\n",
        "Validacion = True #@param {type:\"boolean\"}\n",
        "\n",
        "!rm -rf ./logs/ #Limpiar datos TensorBoard \n",
        "\n",
        "if (Validacion):\n",
        "  modelo.fit(x_train, y_train, epochs=Entrenamiento,validation_data=(x_test, y_test),callbacks=[tensorboard_callback] )\n",
        "else:\n",
        "  modelo.fit(x_train, y_train, epochs=Entrenamiento,callbacks=[tensorboard_callback])\n",
        "\n",
        "\"\"\"#GRAFICO\n",
        "tipo_arq=\"RNA\" if (RNA) else \"RNC\"\n",
        "plt.figure(figsize=(10,6), facecolor=\"#E8E1E0\")\n",
        "plt.axes(facecolor='#E8E1E0')\n",
        "plt.plot(modelo.history.history['sparse_categorical_accuracy'])  \n",
        "plt.plot(modelo.history.history['val_sparse_categorical_accuracy'],'g')  \n",
        "plt.xticks(np.arange(0, Entrenamiento+1, 1)) \n",
        "plt.xlabel(\"Numero de entrenamientos\")  \n",
        "plt.ylabel(\"Exactitud\")  \n",
        "plt.title(\"Resultados entrenamiento de la {}\".format(tipo_arq) )  \n",
        "plt.grid(color='white')\n",
        "plt.legend(['Imagenes Entrenamiento','Imagenes Test'])\"\"\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ctueTXbJ9E5",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Resultados del Entrenamiento \n",
        "%tensorboard --logdir logs/fit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOo050ihBM9E",
        "colab_type": "text"
      },
      "source": [
        "**Resultados de la Red Neuronal con los datos de Test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7WB-3eAtpNH",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Ejecutar Examen\n",
        "predictions=modelo.predict(x_test) #prediccion para imagenes\n",
        "y_pred_proba = modelo.predict_proba(x_test)  #prediccion probabilidad \n",
        "metricas=modelo.evaluate(x_test,  y_test, verbose=2)\n",
        "print(\"\"\"Exactitud: [{}]\"\"\".format(np.round(metricas[1], decimals=4)) )\n",
        "print(\"\\nMATRIZ DE CONFUSION: \")\n",
        "\n",
        "#MATRIZ DE CONFUSION\n",
        "y_pred = modelo.predict_classes(x_test)\n",
        "mc=pd.crosstab(y_test, y_pred)\n",
        "mc.columns=clasificacion\n",
        "\n",
        "#Generar la exactitud de la Matriz de Confusion \n",
        "prob_mc,i=[],0\n",
        "for i in range (len(mc.iloc[:].values)):\n",
        "  prob_mc.append( (mc.iloc[i,i:i+1].values/sum(mc.iloc[i].values))*100 )\n",
        "\n",
        "#Union de Dataframes\n",
        "matriz_confusion=pd.concat([pd.DataFrame(clasificacion,columns=[\"categoría\"]),\n",
        "                mc,pd.DataFrame(prob_mc,columns=[\"Exactitud(%)\"])],axis=1)\n",
        "\n",
        "#GRAFICO\n",
        "tipo_arq=\"RNA\" if (RNA) else \"RNC\"\n",
        "plt.figure(figsize=(16,3), facecolor=\"#E8E1E0\")\n",
        "#plt.xticks(np.arange(0, Entrenamiento+1, 1)) \n",
        "plt.title(\"Matriz de Confusión {}\".format(tipo_arq) )  \n",
        "plt.ylabel(\"Exactitud(%)\")  \n",
        "autolabel(plt.bar(clasificacion,np.round(np.array(prob_mc).flatten(),decimals=0),\n",
        "                color=\"#5AADF2\") )\n",
        "\n",
        "\n",
        "matriz_confusion"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFweYwdv2JHo",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Guardar resultados del examen \n",
        "path,nom_archivo1,nom_archivo2=\"/content/drive/My Drive/Dataset/\",\"R_ImagenesTF.csv\",\"MC_ImagenesTF.csv\"\n",
        "pd.DataFrame(y_pred_proba,y_test).to_csv(path+nom_archivo1)\n",
        "matriz_confusion.to_csv(path+nom_archivo2)\n",
        "print(\"\"\"Archivo Detalle generado: {}{} \n",
        "\\nArchivo Matriz confusión generado: {}{}\"\"\".format(\n",
        "    path,nom_archivo1,\n",
        "    path,nom_archivo2) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCc1det892-q",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Procesar una Imagen \n",
        "posicion_imagen =  192#@param {type:\"integer\"}\n",
        "i = posicion_imagen\n",
        "plt.figure(figsize=(6,3),facecolor=\"#E8E1E0\")\n",
        "plt.subplot(1,2,1)\n",
        "plot_image(i, predictions[i], y_test, x_test)\n",
        "plt.subplot(1,2,2)\n",
        "plot_value_array(i, predictions[i], y_test)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGzKX3muEHtK",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Procesar varias imagenes \n",
        "num_rows =  10#@param {type:\"integer\"}\n",
        "ini_imagen =  0#@param {type:\"integer\"}\n",
        "num_cols=5\n",
        "\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows),facecolor=\"#E8E1E0\")\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image(i+ini_imagen, predictions[i+ini_imagen], y_test, x_test)\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
        "  plot_value_array(i+ini_imagen, predictions[i+ini_imagen], y_test)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR9Jywo7CLZk",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Guardar archivo \n",
        "\"\"\"import sys\n",
        "if 'google.colab' in sys.modules:\n",
        "  from google.colab import auth as google_auth\n",
        "  google_auth.authenticate_user()\"\"\"\n",
        "\n",
        "#archivo=path+\"ARQ_ImagenesTF.json\"\n",
        "archivo=path+\"ARQ_ImagenesTF\"\n",
        "modelo_json = modelo.to_json()\n",
        "with open(\"{}.json\".format(archivo), \"w\") as json_file:\n",
        "    json_file.write(modelo_json)\n",
        "print(\"Archivo creado (Arquitectura): {}.json\".format(archivo))\n",
        "\n",
        "#Guardar los pesos de la Red Neuronal\n",
        "modelo.save_weights(\"{}_pesos.h5\".format(archivo))\n",
        "print(\"Archivo creado (Weights): {}_pesos.h5\".format(archivo))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoarivRPn_eM",
        "colab_type": "text"
      },
      "source": [
        "# Aprendizaje por Transferencia \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQbn5JGP1PHS",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Cargar Dataset\n",
        "#CARGAR DATOS DESDE GCS\n",
        "path_storage=\"001_storage/Datasets/cats_and_dogs/\"\n",
        "archivo = \"cats_and_dogs.zip\"\n",
        "!gsutil cp gs://{path_storage}{archivo} /content/{archivo}\n",
        "\n",
        "#DESCOMPRIMIR DATASET \n",
        "dataset_path = \"./{}\".format(archivo)\n",
        "zip_object = zipfile.ZipFile(file=dataset_path, mode=\"r\")\n",
        "zip_object.extractall(\"./\")\n",
        "zip_object.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKCDrvOYoEdL",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Redimensionar los datos \n",
        "#https://keras.io/api/preprocessing/image/ \n",
        "\n",
        "#VARIABLES INICIALES\n",
        "imagen_size = 224\n",
        "batch_size = 10\n",
        "\n",
        "#DIRECTORIO DE LOS DATOS \n",
        "dataset_path_new = \"./cats_and_dogs_filtered/\"\n",
        "train_dir = os.path.join(dataset_path_new, \"train\")\n",
        "validation_dir = os.path.join(dataset_path_new, \"validation\")\n",
        "\n",
        "\n",
        "#ESCALAR LAS IMAGENES \n",
        "data_gen_train = ImageDataGenerator(rescale=1/255.)\n",
        "data_gen_valid = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "\n",
        "#ESTANDARIZAR TAMAÑO DE LAS IMAGENES \n",
        "print(\"Imagenes de entrenamiento detectadas:\")\n",
        "imagenes_train = data_gen_train.flow_from_directory(\n",
        "    train_dir, \n",
        "    target_size=(imagen_size,imagen_size), \n",
        "    batch_size=batch_size, \n",
        "    class_mode=\"categorical\")\n",
        "\n",
        "\n",
        "print(\"\\nImagenes de validación detectadas:\")\n",
        "imagenes_test = data_gen_valid.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(imagen_size,imagen_size), \n",
        "    batch_size=batch_size, \n",
        "    class_mode=\"categorical\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wddGF3u_uO5I",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Modificar Arquitectura Base Red Neuronal\n",
        "#CARGAR MODELO BASE \n",
        "tamanio_imagen = (imagen_size, imagen_size, 3)\n",
        "modelo_base = tf.keras.applications.DenseNet201(\n",
        "    input_shape=tamanio_imagen,\n",
        "    include_top=False, \n",
        "    weights=\"imagenet\")\n",
        "\n",
        "#DEFINIR CAPAS QUE SE VAN AGREGAR AL MODELO BASE\n",
        "modelo_base.trainable = False  #Congelar modelo Base\n",
        "modelo_head = tf.keras.layers.GlobalAveragePooling2D()(modelo_base.output) #Agregamos capa AveragePooling \n",
        "modelo_head = tf.keras.layers.Dense(units=2, activation='softmax')(modelo_head)\n",
        "\n",
        "#AGREGAR CAPAS AL MODELO BASE\n",
        "modelo = tf.keras.models.Model(inputs=modelo_base.input, outputs=modelo_head)\n",
        "modelo.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.0001), \n",
        "              loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "modelo.summary() #Resumen de la nueva arquitectura Red Neuronal  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LEzn0r0qx00",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "tamanio_imagen = (224, 224, 3)\n",
        "modelo_base = tf.keras.applications.DenseNet201(\n",
        "    input_shape=tamanio_imagen,\n",
        "    include_top=True, \n",
        "    weights=\"imagenet\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kaEFeI8NxNs1",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Entrenar a la Red Neuronal\n",
        "Entrenamiento =  3#@param {type:\"number\"}\n",
        "\n",
        "!rm -rf ./logs/ #Limpiar datos TensorBoard \n",
        "modelo.fit(imagenes_train,\n",
        "           epochs=Entrenamiento, \n",
        "           validation_data=imagenes_test,\n",
        "           callbacks=[tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqpzzDORnv0y",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Evaluar exactitud del modelo\n",
        "%tensorboard --logdir logs/fit\n",
        "set_datos=imagenes_test\n",
        "valid_loss, exactitud_test = modelo.evaluate(set_datos)\n",
        "print(\"\"\"{} imagenes analizadas \n",
        "El modelo clasifico {:,.0f} imagenes correctamente, {:,.2f}% de exactitud\"\"\".format(len(set_datos.filenames),\n",
        "                                                        len(set_datos.filenames)*exactitud_test,\n",
        "                                                        exactitud_test*100,) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcLfmaedKr_w",
        "colab_type": "text"
      },
      "source": [
        "**APLICAR FINE TUNNING AL MODELO**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nrDewMoy45C7",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "57fd1540-93c3-43cc-cb83-d9b1b0628182"
      },
      "source": [
        "#@title Desabilitar y mostrar numero de capas del modelo\n",
        "# Se desabilita el todo el modelo base para poder ser modificado\n",
        "modelo_base.trainable = True\n",
        "print(\"Numero de capas del modelo base: {}\".format(\n",
        "    len(modelo_base.layers)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Numero de capas del modelo base: 707\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVIbUwUnLBhg",
        "colab_type": "code",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae6b5f88-44b3-4c34-fc62-28f2cfdae00c"
      },
      "source": [
        "#@title Congelar Capas \n",
        "capas_congelar =  600#@param {type:\"number\"}\n",
        "for layer in modelo_base.layers[:capas_congelar]:\n",
        "    layer.trainable = False\n",
        "print(\"Se congelaron las primeras {} capas del modelo base\".format(capas_congelar) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Se congelaron las primeras 600 capas del modelo base\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdgG-4KALW3R",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Entrenar nuevamente el modelo\n",
        "Entrenamiento_ft =  5#@param {type:\"number\"}\n",
        "\n",
        "modelo.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "modelo.fit(imagenes_train,  \n",
        "                    epochs=Entrenamiento_ft, \n",
        "                    validation_data=imagenes_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndm-aRBUL_Gx",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Resultados imagenes Test - Fine Tunning\n",
        "valid_loss, exactitud_test = modelo.evaluate(valid_generator)\n",
        "print(\"El modelo tiene una exactitud del {:,.2f}% con las imagenes de prueba \".format(exactitud_test*100) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6-Pcb5WuX0F",
        "colab_type": "text"
      },
      "source": [
        "Pruebas con imagenes\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rNlF52bH3CH",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Procesar imagen\n",
        "# Identificar imagenes \n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "#Predecir imagenes \n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():   \n",
        "  path = fn\n",
        "  img = image.load_img(path, target_size=(imagen_size,imagen_size) )\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  x= x/255\n",
        "  images = np.vstack([x])\n",
        "  classes = modelo.predict(x, batch_size=batch_size)\n",
        "\n",
        "print(\"Probabilidad Gato: {}%\".format(np.round(classes[:,0].flatten()*100, 2)) )\n",
        "print(\"Probabilidad Perro: {}%\".format(np.round(classes[:,1].flatten()*100, 2)) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9Z076bUYFcs",
        "colab_type": "text"
      },
      "source": [
        "# Clasificación healt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87yW_KKVXuEU",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Cargar Dataset\n",
        "#CARGAR DATOS DESDE GCS\n",
        "path_storage=\"001_storage/Datasets/\"\n",
        "archivo = \"Neumonia.zip\"\n",
        "!gsutil cp gs://{path_storage}{archivo} /content/{archivo}\n",
        "\n",
        "#DESCOMPRIMIR DATASET \n",
        "print(\"Descomprimiento archivo ...\")\n",
        "dataset_path = \"./{}\".format(archivo)\n",
        "zip_object = zipfile.ZipFile(file=dataset_path, mode=\"r\")\n",
        "zip_object.extractall(\"./\")\n",
        "zip_object.close()\n",
        "print(\"Proceso Finalizado con exito !!!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3hIQGIlXOUH",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Inicializar variables \n",
        "imagen_size = 150\n",
        "batch_size = 126\n",
        "color_mode = \"grayscale\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFkOpH5aeylW",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Cargar imagenes\n",
        "#https://keras.io/api/preprocessing/image/\n",
        "#DIRECTORIO DE LOS DATOS \n",
        "dataset_path_new = \"./chest_xray/\"\n",
        "train_dir = os.path.join(dataset_path_new, \"train\")\n",
        "validation_dir = os.path.join(dataset_path_new, \"test\")\n",
        "\n",
        "#ESCALAR LAS IMAGENES \n",
        "#data_gen_train = ImageDataGenerator(rescale=1/255.)\n",
        "data_gen_train = ImageDataGenerator(\n",
        "      rescale = 1./255,\n",
        "\t    rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "data_gen_valid = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "#ESTANDARIZAR TAMAÑO DE LAS IMAGENES \n",
        "print(\"Imagenes de entrenamiento detectadas:\")\n",
        "imagenes_train = data_gen_train.flow_from_directory(\n",
        "    train_dir, \n",
        "    target_size=(imagen_size,imagen_size),\n",
        "    batch_size=batch_size, \n",
        "    color_mode=color_mode,\n",
        "    class_mode=\"categorical\")\n",
        "    \n",
        "print(\"\\nImagenes de prueba detectadas:\")\n",
        "imagenes_test = data_gen_valid.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(imagen_size,imagen_size), \n",
        "    batch_size=batch_size,\n",
        "    color_mode=color_mode,\n",
        "    class_mode=\"categorical\")\n",
        "\n",
        "print(\"\"\"\\n- Nombre imagenes de Entrenamiento: imagenes_train\n",
        "- Nombre imagenes de prueba: imagenes_test\"\"\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmFYrNVzjv-R",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Arquitectura por transferencia \n",
        "#CARGAR MODELO BASE \n",
        "tamanio_imagen = (imagen_size, imagen_size, 3)\n",
        "modelo_base = tf.keras.applications.DenseNet201(\n",
        "    input_shape=tamanio_imagen,\n",
        "    include_top=False, \n",
        "    weights=\"imagenet\")\n",
        "\n",
        "#DEFINIR CAPAS QUE SE VAN AGREGAR AL MODELO BASE\n",
        "modelo_base.trainable = False  #Congelar modelo Base\n",
        "modelo_head = tf.keras.layers.GlobalAveragePooling2D()(modelo_base.output) #Agregamos capa AveragePooling \n",
        "modelo_head = tf.keras.layers.Flatten()(modelo_head)\n",
        "modelo_head = tf.keras.layers.Dense(128, activation='relu')(modelo_head)\n",
        "modelo_head = tf.keras.layers.Dropout(0.5)(modelo_head)\n",
        "modelo_head = tf.keras.layers.Dense(units=2, activation='softmax')(modelo_head)\n",
        "\n",
        "#AGREGAR CAPAS AL MODELO BASE\n",
        "modelo = tf.keras.models.Model(inputs=modelo_base.input, outputs=modelo_head)\n",
        "modelo.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.0001), \n",
        "              loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "modelo.summary() #Resumen de la nueva arquitectura Red Neuronal  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdhDHpLUvqn5",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "modelo_base.trainable = True\n",
        "print(\"Numero de capas del modelo base: {}\".format(\n",
        "    len(modelo_base.layers)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6iv-7ulvzCr",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "capas_congelar =  600#@param {type:\"number\"}\n",
        "for layer in modelo_base.layers[:capas_congelar]:\n",
        "    layer.trainable = False\n",
        "print(\"Se congelaron las primeras {} capas del modelo base\".format(capas_congelar) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EG1LBTQ4oyXQ",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Arquitectura CNN\n",
        "#Arquitectura de la Red Neuronal Convolucional (Ajustar imagen a 150x150 pixeles)\n",
        "modelo = tf.keras.models.Sequential([\n",
        "    # El tamaño de la imagen de entrada debe ser de 150x150 pixeles con 3 bytes color (input_shape)\n",
        "    # Primera capa de convolucion con 64 filtros de tamaño 3x3 y capa MaxPooling tamaño 2x2 (Función activación: Rectificador Lineal)\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(imagen_size, imagen_size, 1)), \n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    \n",
        "    # Segunda capa de convolución  con 64 filtros de tamaño 3x3 y capa MaxPooling tamaño 2x2 \n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "    # Tercera capa de convolución  con 128 filtros de tamaño 3x3 y capa MaxPooling tamaño 2x2\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "    # Cuarta capa de convolución  con 128 filtros de tamaño 3x3 y capa MaxPooling tamaño 2x2\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "    # Capa de aplando para la entrada a la red neuronal y Dropout para evitar overfitting \n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    \n",
        "    # 512 neuronas de capa oculta y funcion de salida softmax (Clasificará 3 tipos de imagenes)\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "#Documentación del RMSprop: https://keras.io/api/optimizers/rmsprop/\n",
        "modelo.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.0001),\n",
        "               loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "modelo.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v70HF5V0g4RQ",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Entrenar a la Red Neuronal\n",
        "Entrenamiento =  25#@param {type:\"number\"}\n",
        "\n",
        "!rm -rf ./logs/ #Limpiar datos TensorBoard \n",
        "modelo.fit(imagenes_train,\n",
        "           validation_data=imagenes_test,\n",
        "           epochs=Entrenamiento,            \n",
        "           callbacks=[tensorboard_callback])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXbfLSE7hGee",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Procesar imagen\n",
        "# Identificar imagenes \n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "#Cargar y Predecir imagenes \n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():   \n",
        "  path = fn\n",
        "  img = image.load_img(path,\n",
        "                       target_size=(imagen_size,imagen_size),\n",
        "                       color_mode=color_mode)\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  x= x/255\n",
        "  #imagen = np.vstack([x])\n",
        "  classes = modelo.predict(x,batch_size=imagen_size)\n",
        "\n",
        "print(\"Probabilidad normal: {}%\".format(np.round(classes[:,0].flatten()*100, 2)) )\n",
        "print(\"Probabilidad neumonia: {}%\".format(np.round(classes[:,1].flatten()*100, 2)) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGQXwmPV3wQ1",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Cargar pesos del modelo entrenado\n",
        "Archivo_modelo = \"09165_Neumonia.h5\" #@param {type:\"string\"}\n",
        "\n",
        "#from keras.models import load_model\n",
        "path_storage=\"001_storage/modelos/Healt/Naumonia/\"\n",
        "!gsutil cp gs://{path_storage}{Archivo_modelo} /content/{Archivo_modelo}\n",
        "\n",
        "modelo.load_weights(Archivo_modelo)\n",
        "print(\"Modelo entrenado cagado exitosamente !!!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmim3jrXXDAI",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Evaluar exactitud del modelo\n",
        "set_datos=imagenes_test\n",
        "valid_loss, exactitud_test = modelo.evaluate(set_datos)\n",
        "print(\"\"\"{} imagenes analizadas \n",
        "El modelo clasifico {:,.0f} imagenes correctamente, {:,.2f}% de exactitud\"\"\".format(len(set_datos.filenames),\n",
        "                                                        len(set_datos.filenames)*exactitud_test,\n",
        "                                                        exactitud_test*100,) )"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}